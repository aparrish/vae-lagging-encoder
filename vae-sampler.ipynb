{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling the VAE\n",
    "\n",
    "By [Allison Parrish](http://www.decontextualize.com/)\n",
    "\n",
    "I wrote a little helper class to make it easier to sample strings from the variational autoencoder (VAE) model—in particular, models trained with tokens and embeddings from [BPEmb](https://nlp.h-its.org/bpemb/). This notebook takes you through the functionality, using the `poetry_1m_sample` model I trained (see README for download instructions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, importlib\n",
    "import torch\n",
    "from vaesampler import BPEmbVaeSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load the configuration and assign the parameters to a `Namespace` object. Then, create the `BPEmbVaeSampler` object with the same `bpemb` parameters used to train the model and the path to the pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/allison/Dropbox/projects/vae-lagging-encoder/env/lib/python3.7/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "config_file = \"config.config_poetry_1m_sample\"\n",
    "params = argparse.Namespace(**importlib.import_module(config_file).params)\n",
    "bpvs = BPEmbVaeSampler(lang=params.bpemb['lang'], vs=params.bpemb['vs'], dim=params.bpemb['dim'],\n",
    "                       decode_from=\"./models/poetry_1m_sample/2019-08-20T03:32:25.569351-012.pt\",\n",
    "                       params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the size of the latent space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_size = params.nz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding\n",
    "\n",
    "The main thing you'll want to do is decode strings from a latent variable `z`. This variable has a Gaussian distribution (or at least it *should*—that's the whole point of a VAE, right?). There are three methods for decoding strings from `z`:\n",
    "\n",
    "* `.sample()` samples the (softmax) distribution of the output with the given temperature at each step;\n",
    "* `.greedy()` always picks the most likely next token;\n",
    "* `.beam()` expands multiple \"branches\" of the output and returns the most likely branch\n",
    "\n",
    "(These methods use the underlying implementations in the `LSTMDecoder` class provided in the original repository.)\n",
    "\n",
    "Below you'll find some examples of each. First, `.sample()` with a temperature of 0.5. (Increase the temperature for more unlikely output; it approximates `.greedy()` as the temperature approaches 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hawves of riches of sea,\n",
      "A stranger of the moon, and then\n",
      "Because to be like a more of a simple blast,\n",
      "Insects and poor lady, by thy name,\n",
      "Scorns to meet; and he was one; and of the dreadful\n",
      "And join my words out of some dark was hand\n",
      "The sun-sas!\n",
      "Their leaves of various flowers\n",
      "Dewy el el mundo violets lingering,\n",
      "Follow'd far on foes of glory,\n",
      "Under the swan, and banishing to gain; as the weary\n",
      "Only terrible to hear him.\n",
      "Never gave us, and thy own is given.\n",
      "I know, for there, and many a pair\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"\\n\".join(bpvs.sample(torch.randn(14, z_size), temperature=0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greedy decoding (usually less interesting):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not a heart of mine.\n",
      "Instead of these things, all of earth.\n",
      "And like a road to me.\n",
      "That we are\n",
      "To, with a fury, bound, and all, and all the rest.\n",
      "Pisto's who are to thee, and to thee to bewildered\n",
      "That motion of his hand and silvery\n",
      "At least, nor turn, and hither, and our bands,\n",
      "The hermit's head, and, round the iron walls\n",
      "And, put away with a little-night\n",
      "The bees are like a glowing sun,\n",
      "As a new-souled, and the greeks\n",
      "Making his counsellor in his rank of pain\n",
      "Which of a day of thee that is a single hand.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"\\n\".join(bpvs.greedy(torch.randn(14, z_size))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beam search (a good compromise, but slow):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As to thee-groom still,\n",
      "Let him with his mynge\n",
      "Among those sons of hiaw.\n",
      "And now I'm better for a thousand years,\" he said, \"that, who\n",
      "Whirled in her bosom glow\n",
      "And saw awhile alone\n",
      "So grandeur's bosom of sorrow!\n",
      "My spirit leaps,\n",
      "So I am not a patriot of my thought\n",
      "Then, the ship-glass together,\n",
      "A steeds, and of a loveliness\n",
      "And how I know\n",
      "He was the silken, and brav\n",
      "When I saw a mists of crimson,\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"\\n\".join(bpvs.beam(torch.randn(14, z_size), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homotopies (linear interpolation)\n",
    "\n",
    "Using the VAE, you can explore linear interpolations between two lines of poetry. The code in the cell below picks two points at random in the latent space and decodes at evenly-spaced points between the two. (I've included commented-out calls to different decoding methods do make it easy to experiment with them.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A voice of waters;\n",
      "While a voice of light\n",
      "While a voice of morning;\n",
      "While sudden a cloud of tears\n",
      "Who saw a cloud of tears\n",
      "Who saw a meteor of the gale;\n",
      "Did sometimes a cloud of rain;\n",
      "Did sometimes a meteor of the gale;\n",
      "Did sometimes a bubble of the gale;\n",
      "Did sometimes a bubble of the gale;\n",
      "Did sometimes a song of the slow gale;\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x = torch.randn(1, z_size)\n",
    "    y = torch.randn(1, z_size)\n",
    "    steps = 10\n",
    "    for i in range(steps + 1):\n",
    "        z = (y * (i/steps)) + (x * (1-(i/steps)))\n",
    "        print(bpvs.greedy(z)[0])\n",
    "        #print(bpvs.sample(z, 0.35)[0])\n",
    "        #print(bpvs.beam(z, 3)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this same logic, you can produce variations on a line of poetry by adding a bit of random noise to the vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large and the forest of a magic flame.\n",
      "Large and the forest of a strange surprise.\n",
      "Large and the forest of a magic gale.\n",
      "Large and the forest of a strange disease.\n",
      "Large and the forest of a magic.\n",
      "Large and the golden circle of melody.\n",
      "Large and the forest of a strange.\n",
      "Large and the forest of a strange.\n",
      "Large and the forest of a strange emotion.\n",
      "Large and the forest of a strange emotion.\n",
      "Large and the forest of its subtle.\n",
      "Large and the forest of a strange emotion.\n",
      "Large and the forest, like a strange.\n",
      "Large and the forest of a magic.\n",
      "Large and the circle of a precious flame.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x = torch.randn(1, z_size)\n",
    "    steps = 14\n",
    "    for i in range(steps + 1):\n",
    "        z = x + (torch.randn(1, z_size)*0.1)\n",
    "        print(bpvs.greedy(z)[0])\n",
    "        #print(bpvs.sample(z, 0.35)[0])\n",
    "        #print(bpvs.beam(z, 4)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggested by [@halcy@icosahedron.website](https://icosahedron.website/@halcy/102650042038601749): decoding from points on a randomly-selected circular path (halcy notes that this is \"actually 'only' an ellipse unless ab and ac are orthogonal, which for high dimensional vectors picked randomly is pretty likely to be approximately true\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def circ_generator(a, b, c, steps, radius=1):\n",
    "    lerp = np.linspace(0, 1, steps).reshape(-1, 1)\n",
    "    axis_x = (a - b).flatten() / np.linalg.norm(a - b)\n",
    "    axis_y = (a - c).flatten() / np.linalg.norm(a - c)\n",
    "    latents_x = np.sin(np.pi * 2.0 * lerp) * radius\n",
    "    latents_y = np.cos(np.pi * 2.0 * lerp) * radius\n",
    "    latents = a + (latents_x * axis_x) + (latents_y * axis_y)\n",
    "    return torch.tensor(latents).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rich and softly weeping thee\n",
      "Rich and softly, and weeds again\n",
      "Rich and silently, and weeping\n",
      "Rich and silently; and, and weeds\n",
      "Muteous, sobs, and all the ground\n",
      "Muteous; and then, as he shall rise\n",
      "Mellowed, and shining in their way;\n",
      "Muteous smoke, and fills the ground;\n",
      "Full of a graces of the foe;\n",
      "Full of myriad and thee\n",
      "Rich and sweetly and the angels blow\n",
      "Rich and softly weeping thee\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    a = np.random.randn(z_size)\n",
    "    b = np.random.randn(z_size)\n",
    "    c = np.random.randn(z_size)\n",
    "    circ = circ_generator(a, b, c, 12, 5)\n",
    "    #out = bpvs.greedy(circ)\n",
    "    #out = bpvs.sample(circ, 0.5)\n",
    "    out = bpvs.beam(circ, 4)\n",
    "    print(\"\\n\".join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructions\n",
    "\n",
    "You can ask the model to produce the latent vector for any given input. (Using `BPEmb` helps ensure that arbitrary inputs won't fail because of out-of-vocabulary tokens.) The latent vector is given as a Gaussian distribution—a mean (`mu`) and a variance. You can either sample from this distribution with `.z()` or just get the mean with `.mu()`.\n",
    "\n",
    "You can then pass this to `.sample()`, `.beam()`, or `.greedy()` to produce a string. The model's reconstructions aren't super accurate, but you can usually see some hint of the original string's meaning or structure in the output. Here I'm experimenting with H.D.'s 1916 poem \"Sea Rose\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "strs = \"\"\"\\\n",
    "Rose, harsh rose, \n",
    "marred and with stint of petals, \n",
    "meagre flower, thin, \n",
    "spare of leaf,\n",
    "more precious \n",
    "than a wet rose \n",
    "single on a stem -- \n",
    "you are caught in the drift.\n",
    "Stunted, with small leaf, \n",
    "you are flung on the sand, \n",
    "you are lifted \n",
    "in the crisp sand \n",
    "that drives in the wind.\n",
    "Can the spice-rose \n",
    "drip such acrid fragrance \n",
    "hardened in a leaf?\"\"\".split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell shows the original poem along with its reconstruction, calculating from the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rose, harsh rose,                  Rose, like a sudden, and\n",
      "marred and with stint of petals,   Marred and a hundred miles of gold,\n",
      "meagre flower, thin,               Dripping, sweet, and fair\n",
      "spare of leaf,                     Little a thousand, as a thousand way\n",
      "more precious                      More precious as a pilgrim's heart\n",
      "than a wet rose                    As a little wind was silent in\n",
      "single on a stem --                Without a leaf of a thousand-born\n",
      "you are caught in the drift.       You are not in the western sea.\n",
      "Stunted, with small leaf,          Stunted, like a thousand-hearted,\n",
      "you are flung on the sand,         You are not on the sandals,\n",
      "you are lifted                     They are not a thousand-eyed hand\n",
      "in the crisp sand                  In the crisp of silver-waves\n",
      "that drives in the wind.           That opens in the sky. He saw\n",
      "Can the spice-rose                 Let the grape-tree of a way\n",
      "drip such acrid fragrance          Dripping a golden goblet\n",
      "hardened in a leaf?                Hardened in a leafy tree;\n"
     ]
    }
   ],
   "source": [
    "llen = max([len(item) for item in strs])\n",
    "with torch.no_grad():\n",
    "    sampled = bpvs.greedy(bpvs.mu(strs))\n",
    "    for orig, line in zip(strs, sampled):\n",
    "        print(orig.ljust(llen+1), line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A beam search based on a sample from the latent Gaussian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rose, harsh rose,                  Lo, like a voice of night,\n",
      "marred and with stint of petals,   Perchance and gold of gold,\n",
      "meagre flower, thin,               Sweet beauty, like a moral,\n",
      "spare of leaf,                     The leafy trees, and very long\n",
      "more precious                      As sweetness of my native strife,\n",
      "than a wet rose                    As a little white-winged plaid;\n",
      "single on a stem --                Without a single-place of france\n",
      "you are caught in the drift.       We are singing in the laughter fly;\n",
      "Stunted, with small leaf,          Read, in a narrow space of pain,\n",
      "you are flung on the sand,         Go down on the grass of rain,\n",
      "you are lifted                     You are just and uncoated,\n",
      "in the crisp sand                  With the pavement of a squire\n",
      "that drives in the wind.           My eyes in the window, and white\n",
      "Can the spice-rose                 Now the bird-winds a sudden air\n",
      "drip such acrid fragrance          Unto a melancholy veil,\n",
      "hardened in a leaf?                Leaned in vain, an honest man.\n"
     ]
    }
   ],
   "source": [
    "llen = max([len(item) for item in strs])\n",
    "with torch.no_grad():\n",
    "    sampled = bpvs.beam(bpvs.z(strs), 4)\n",
    "    for orig, line in zip(strs, sampled):\n",
    "        print(orig.ljust(llen+1), line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And rewriting the poem, line by line, sampling the softmax layer with increasing temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Like a sudden,\n",
      "Woven and kind of all a sound,\n",
      "My song, little little,\n",
      "Made a world,\n",
      "So pure,\n",
      "Of a nightmare bird\n",
      "Seems a single tale!\"\n",
      "If before its sounding notes.\n",
      "Approcar, made it a leaf,\n",
      "Giveed his cradle and red,\n",
      "May tromor;\n",
      "And through zomb a blood,\n",
      "And rain with descriptive unionist?\n",
      "Seemed mritting disappointment april lumber\n",
      "Meantime qualification rise panic en friday clouds\n",
      "Litted that vault another rocketsorn another makers\n"
     ]
    }
   ],
   "source": [
    "max_temp = 2.0\n",
    "with torch.no_grad():\n",
    "    for i, line in enumerate(strs):\n",
    "        sampled = bpvs.sample(bpvs.z([line]),\n",
    "                              max_temp * (i/len(strs)) + 1e-5)\n",
    "        print(sampled[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variations on a single line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "His son of a look o'er her head\n",
      "His brow is still a wild wind of\n",
      "The sighs of wretched and cold\n",
      "The scanty sighs of meek\n",
      "His boy's voice is shining through\n",
      "The gany's voice of softly rain\n",
      "His wretched and a smile of yesterday\n",
      "His mother's face is darkened a\n",
      "His chime and slumbering of me\n",
      "The lion's heart is shining of me\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    center = bpvs.mu([\"My cat's breath smells like cat food\"])\n",
    "    print(bpvs.sample(center, 0.35)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And interpolating between two specified lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two roads diverged in a yellow wood,\n",
      "Two miles out of a window-tree\n",
      "Two miles came up in a single tree,\n",
      "Scarce came back a book of a string,\n",
      "Although I found a little house of a ball,\n",
      "As he was taken in a little stone,\n",
      "As they had taken a little aisle,\n",
      "As he was going to a single stone,\n",
      "And he was seen with a single line,\n",
      "And he was seen to make a stone.\n",
      "And he was seen to a very stone.\n",
      "And he was always a little space.\n",
      "And he was always in a single case.\n",
      "And he was very much in his case.\n",
      "And that has made all the difference.\n"
     ]
    }
   ],
   "source": [
    "start_s = \"Two roads diverged in a yellow wood,\"\n",
    "end_s = \"And that has made all the difference.\"\n",
    "with torch.no_grad():\n",
    "    x = bpvs.z([start_s])\n",
    "    y = bpvs.z([end_s])\n",
    "    steps = 12\n",
    "    print(start_s)\n",
    "    for i in range(steps + 1):\n",
    "        z = (y * (i/steps)) + (x * (1-(i/steps)))\n",
    "        print(bpvs.sample(z, 0.25)[0])\n",
    "        #print(bpvs.greedy(z)[0])\n",
    "        #print(bpvs.beam(z, 4)[0])\n",
    "    print(end_s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
