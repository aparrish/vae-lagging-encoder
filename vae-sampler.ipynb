{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling the VAE\n",
    "\n",
    "By [Allison Parrish](http://www.decontextualize.com/)\n",
    "\n",
    "I wrote a little helper class to make it easier to sample strings from the VAE model—in particular, models trained with tokens from `bpemb`. This notebook takes you through the functionality, using the included `poetry_500k_sample` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, importlib\n",
    "import torch\n",
    "from vaesampler import BPEmbVaeSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load the configuration and assign the parameters to a `Namespace` object. Then, create the `BPEmbVaeSampler` object with the same `bpemb` parameters used to train the model and the path to the pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/allison/Dropbox/projects/vae-lagging-encoder/env/lib/python3.7/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "config_file = \"config.config_poetry_500k_sample\"\n",
    "params = argparse.Namespace(**importlib.import_module(config_file).params)\n",
    "bpvs = BPEmbVaeSampler(lang='en', vs=10000, dim=100,\n",
    "                       decode_from=\"./models/poetry_500k_sample/2019-08-09T08:27:43.289493-011.pt\",\n",
    "                       params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding\n",
    "\n",
    "The main thing you'll want to do is decode strings from a latent variable `z`. This variable has a Gaussian distribution (or at least it *should*—that's the whole point of a VAE, right?). There are three methods for decoding strings from `z`:\n",
    "\n",
    "* `.sample()` samples the (softmax) distribution of the output with the given temperature at each step;\n",
    "* `.greedy()` always picks the most likely next token;\n",
    "* `.beam()` expands multiple \"branches\" of the output and returns the most likely branch\n",
    "\n",
    "(These methods use the underlying implementations in the `LSTMDecoder` class.)\n",
    "\n",
    "Below you'll find some examples of each. First, `.sample()` with a temperature of 1.0. (Increase the temperature for more unlikely output; it approximates `.greedy()` as the temperature approaches 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some painted\n",
      "As the mind would reach in funeral hand!\n",
      "On three vain gives nitence minstrels poets and any solemerus fly:\n",
      "The glides pass in air to side their one;\n",
      "The throne that kill of king,\n",
      "'tis dread melanse of the deep white sublime,\n",
      "Nor flame like life or wood.\n",
      "To line the meadowing throat like vigorous flower. For even o'er the\n",
      "(nell for I can have exultes,\n",
      "But the spiritual king of greece;\n",
      "Thus thus they wilt the greatest house they gain.\n",
      "And slept at times in the secret loud\n",
      "In least essence worship the fearfully plumes;\n",
      "A wife in youth: these exads, honest two shagci\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"\\n\".join(bpvs.sample(torch.randn(14, 32), temperature=1.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greedy decoding (usually boring):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To the king, and the great and the night,\n",
      "The wildly arose.\n",
      "\"and is thee, and thee, and the _thee_\n",
      "When the first of the world.\n",
      "The old man's sons of the earth\n",
      "And I know thee and thee,\n",
      "The wind of the old man's hand.\n",
      "When the great of the old man's feet\n",
      "I know it, and the same,\n",
      "I have seen, and a young man,\n",
      "And I have been in the air.\n",
      "The mists of the old-born eyes.\n",
      "A thousand years in the house.\n",
      "That I have been in the world.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"\\n\".join(bpvs.greedy(torch.randn(14, 32))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beam search (a good compromise, but slow):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To make thee with all the world of the earth\n",
      "There came in the sea\n",
      "If the wind of the wind,\n",
      "And ráma's self--and's bliss.\n",
      "On the fiery wrought, and\n",
      "As I'll have seen thee.\n",
      "When I'll give thee,\n",
      "But, if I know, and they\n",
      "This is the sunset\n",
      "To whom I have not not, I'll see.\n",
      "Beheld them in the darkness, and in all,\n",
      "A woman's eyes, and with anger\n",
      "I have the golden\n",
      "If I have seen them, and in his hand.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"\\n\".join(bpvs.beam(torch.randn(14, 32), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homotopies (linear interpolation)\n",
    "\n",
    "Using the VAE, you can explore linear interpolations between two lines of poetry. The code in the cell below picks two points at random in the latent space and decodes at evenly-spaced points between the two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And, when the leaves of the sky.\n",
      "That, the leaves of the wind.\n",
      "As the wind of the wind.\n",
      "As the leaves of the sky.\n",
      "As the wind of the wind.\n",
      "That, the wind of the sky.\n",
      "That, the wind of the sky.\n",
      "That, the wind of the sky.\n",
      "When, when the sun\n",
      "When the sun of the sky.\n",
      "I saw the sun\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x = torch.randn(1, 32)\n",
    "    y = torch.randn(1, 32)\n",
    "    steps = 10\n",
    "    for i in range(steps + 1):\n",
    "        z = (x * (i/steps)) + (y * 1-(i/steps))\n",
    "        #print(bpvs.sample(z, 0.2)[0])\n",
    "        #print(bpvs.greedy(z)[0])\n",
    "        print(bpvs.beam(z, 3)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this same logic, you can produce variations on a line of poetry by adding a bit of random noise to the vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the windless and strange,\n",
      "When I have heard the rustling, and with the earthly flame,\n",
      "The red and a moment, and a vain;\n",
      "A man and the sunshine,\n",
      "When the wildness of the night, and the lips of the dear,\n",
      "A little face, and the great and the same.\n",
      "Than the first birds in the darkness, and the careless,\n",
      "When I have been the sunset, and the music of the earth.\n",
      "With the great and weeping, and the lips of the earth.\n",
      "Into the fields of the glorious breeze,\n",
      "To the glory of the grass and dome,\n",
      "Against the sunset, and the long foolish,\n",
      "Down to the world's bosom and aught.\n",
      "When the night to the dreadful eyes.\n",
      "Into the shrillness of the earth and the wall,\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x = torch.randn(1, 32)\n",
    "    steps = 14\n",
    "    for i in range(steps + 1):\n",
    "        z = x + (torch.randn(1, 32)*0.1)\n",
    "        print(bpvs.sample(z, 0.35)[0])\n",
    "        #print(bpvs.greedy(z)[0])\n",
    "        #print(bpvs.beam(z, 4)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructions\n",
    "\n",
    "You can ask the model to produce the latent vector for any given input. (Using `BPEmb` helps ensure that arbitrary inputs won't contain out-of-vocabulary tokens.)\n",
    "\n",
    "The `.z()` method returns a sample from the latent Gaussian, while `.mu()` returns the mean. You can then pass this to `.sample()`, `.beam()`, or `.greedy()` to produce a string. The model's reconstructions aren't very accurate, but you can usually see some hint of the original string's meaning or structure in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "strs = [\"This is just to say\",\n",
    "        \"I have eaten the plums\",\n",
    "        \"That were in the icebox\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['That is not to the sons of the light,',\n",
       " 'This was the shrine of the dead,',\n",
       " 'To the sinkling of the sea']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpvs.sample(bpvs.z(strs), 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To whom I know,',\n",
       " \"I'll have seen them in the air.\",\n",
       " 'As I have seen the sunset']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpvs.beam(bpvs.mu(strs), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To whom the heart of the earth',\n",
       " \"I'll have been the golden breeze,\",\n",
       " 'As the same of the old man,']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpvs.greedy(bpvs.mu(strs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
